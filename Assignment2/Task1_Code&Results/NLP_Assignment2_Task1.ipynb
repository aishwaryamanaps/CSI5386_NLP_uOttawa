{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**NLP Assignment 2**"
      ],
      "metadata": {
        "id": "MJKBbZz6fhxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For this assignment, codes from the provided github link and pre-trained models from HuggingFace have been used."
      ],
      "metadata": {
        "id": "UzTnKHx1fm6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_cU5xfQX8m3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "755681c7-b9e3-4ff5-a7ee-dd6033f7138e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 57.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.24.0\n"
          ]
        }
      ],
      "source": [
        "# Installing pre-requisite\n",
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "UncejtYSQayW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloning CUAD from Git. Manually unzipping the data folder and uploading it to Colab.\n",
        "!git clone https://github.com/TheAtticusProject/cuad.git"
      ],
      "metadata": {
        "id": "vriCJZm0PRmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/cuad/data/train_separate_questions.json\",\"r\") as file:\n",
        "  raw_data=json.load(file)\n",
        "\n",
        "# Taking the first 16 files for training\n",
        "raw_data[\"data\"]=raw_data[\"data\"][0:16]\n",
        "\n",
        "with open(\"model_train.json\",\"w\") as file:\n",
        "  json.dump(raw_data,file)"
      ],
      "metadata": {
        "id": "Qrt5QbRbRO9G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/cuad/data/test.json\",\"r\") as file:\n",
        "  raw_data=json.load(file)\n",
        "\n",
        "# Taking the first 4 files for testing \n",
        "raw_data[\"data\"]=raw_data[\"data\"][0:4]\n",
        "\n",
        "with open(\"model_test.json\",\"w\") as file:\n",
        "  json.dump(raw_data,file)"
      ],
      "metadata": {
        "id": "rkGIr1nlEbyD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bert-Tiny-FineTuned-CUAD"
      ],
      "metadata": {
        "id": "jPBl-U3dcm2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git lfs install\n",
        "! git clone https://huggingface.co/muhtasham/bert-tiny-finetuned-cuad"
      ],
      "metadata": {
        "id": "P-d1QqPTPVJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adcc2167-38ac-4b42-dc6f-296b7d39cf55"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any of the parent directories): .git\\n\"\n",
            "Git LFS initialized.\n",
            "Cloning into 'bert-tiny-finetuned-cuad'...\n",
            "remote: Enumerating objects: 134, done.\u001b[K\n",
            "remote: Counting objects: 100% (134/134), done.\u001b[K\n",
            "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "remote: Total 134 (delta 48), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (134/134), 325.83 KiB | 482.00 KiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "Filtering content: 100% (6/6), 16.71 MiB | 3.77 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! sh /content/cuad/run.sh"
      ],
      "metadata": {
        "id": "3vTuOAiYP_jE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504b5f2b-6bed-4c1d-f6a5-d818ec0ea6be"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:__main__:Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "[INFO|configuration_utils.py:652] 2022-12-01 01:32:07,233 >> loading configuration file /content/bert-tiny-finetuned-cuad/config.json\n",
            "[INFO|configuration_utils.py:706] 2022-12-01 01:32:07,233 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"/content/bert-tiny-finetuned-cuad\",\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-12-01 01:32:07,234 >> loading file vocab.txt\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-12-01 01:32:07,234 >> loading file added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-12-01 01:32:07,234 >> loading file special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-12-01 01:32:07,234 >> loading file tokenizer_config.json\n",
            "[INFO|modeling_utils.py:2155] 2022-12-01 01:32:07,287 >> loading weights file /content/bert-tiny-finetuned-cuad/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:2608] 2022-12-01 01:32:07,347 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
            "\n",
            "[INFO|modeling_utils.py:2616] 2022-12-01 01:32:07,348 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/bert-tiny-finetuned-cuad.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
            "balanced_subset_cached_train_bert-tiny-finetuned-cuad_512\n",
            "100% 16/16 [00:13<00:00,  1.19it/s]\n",
            "convert squad examples to features: 100% 842/842 [08:41<00:00,  1.61it/s]\n",
            "add example index and unique id: 100% 842/842 [00:00<00:00, 59161.79it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch:   0% 0/4 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/92 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/92 [00:02<03:57,  2.61s/it]\u001b[A\n",
            "Iteration:   7% 6/92 [00:02<00:29,  2.94it/s]\u001b[A\n",
            "Iteration:  12% 11/92 [00:02<00:13,  6.11it/s]\u001b[A\n",
            "Iteration:  17% 16/92 [00:02<00:07,  9.97it/s]\u001b[A\n",
            "Iteration:  24% 22/92 [00:03<00:04, 15.35it/s]\u001b[A\n",
            "Iteration:  30% 28/92 [00:03<00:03, 21.28it/s]\u001b[A\n",
            "Iteration:  36% 33/92 [00:03<00:02, 25.61it/s]\u001b[A\n",
            "Iteration:  41% 38/92 [00:03<00:01, 29.37it/s]\u001b[A\n",
            "Iteration:  48% 44/92 [00:03<00:01, 35.41it/s]\u001b[A\n",
            "Iteration:  54% 50/92 [00:03<00:01, 40.79it/s]\u001b[A\n",
            "Iteration:  61% 56/92 [00:03<00:00, 45.09it/s]\u001b[A\n",
            "Iteration:  67% 62/92 [00:03<00:00, 48.32it/s]\u001b[A\n",
            "Iteration:  74% 68/92 [00:03<00:00, 50.93it/s]\u001b[A\n",
            "Iteration:  80% 74/92 [00:03<00:00, 53.09it/s]\u001b[A\n",
            "Iteration:  87% 80/92 [00:04<00:00, 54.28it/s]\u001b[A\n",
            "Iteration: 100% 92/92 [00:04<00:00, 21.38it/s]\n",
            "Epoch:  25% 1/4 [00:04<00:12,  4.30s/it]\n",
            "Iteration:   0% 0/92 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   8% 7/92 [00:00<00:01, 60.04it/s]\u001b[A\n",
            "Iteration:  15% 14/92 [00:00<00:01, 59.26it/s]\u001b[A\n",
            "Iteration:  22% 20/92 [00:00<00:01, 59.06it/s]\u001b[A\n",
            "Iteration:  28% 26/92 [00:00<00:01, 59.08it/s]\u001b[A\n",
            "Iteration:  35% 32/92 [00:00<00:01, 59.07it/s]\u001b[A\n",
            "Iteration:  41% 38/92 [00:00<00:00, 58.26it/s]\u001b[A\n",
            "Iteration:  48% 44/92 [00:00<00:00, 57.92it/s]\u001b[A\n",
            "Iteration:  54% 50/92 [00:00<00:00, 57.45it/s]\u001b[A\n",
            "Iteration:  61% 56/92 [00:00<00:00, 57.18it/s]\u001b[A\n",
            "Iteration:  67% 62/92 [00:01<00:00, 57.65it/s]\u001b[A\n",
            "Iteration:  74% 68/92 [00:01<00:00, 58.04it/s]\u001b[A\n",
            "Iteration:  80% 74/92 [00:01<00:00, 58.31it/s]\u001b[A\n",
            "Iteration:  87% 80/92 [00:01<00:00, 58.35it/s]\u001b[A\n",
            "Iteration: 100% 92/92 [00:01<00:00, 58.56it/s]\n",
            "Epoch:  50% 2/4 [00:05<00:05,  2.70s/it]\n",
            "Iteration:   0% 0/92 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   7% 6/92 [00:00<00:01, 56.47it/s]\u001b[A\n",
            "Iteration:  13% 12/92 [00:00<00:01, 57.01it/s]\u001b[A\n",
            "Iteration:  20% 18/92 [00:00<00:01, 57.86it/s]\u001b[A\n",
            "Iteration:  26% 24/92 [00:00<00:01, 57.77it/s]\u001b[A\n",
            "Iteration:  33% 30/92 [00:00<00:01, 57.67it/s]\u001b[A\n",
            "Iteration:  39% 36/92 [00:00<00:00, 57.61it/s]\u001b[A\n",
            "Iteration:  46% 42/92 [00:00<00:00, 57.97it/s]\u001b[A\n",
            "Iteration:  52% 48/92 [00:00<00:00, 58.15it/s]\u001b[A\n",
            "Iteration:  59% 54/92 [00:00<00:00, 57.71it/s]\u001b[A\n",
            "Iteration:  65% 60/92 [00:01<00:00, 57.99it/s]\u001b[A\n",
            "Iteration:  72% 66/92 [00:01<00:00, 57.89it/s]\u001b[A\n",
            "Iteration:  78% 72/92 [00:01<00:00, 57.08it/s]\u001b[A\n",
            "Iteration:  85% 78/92 [00:01<00:00, 57.29it/s]\u001b[A\n",
            "Iteration:  91% 84/92 [00:01<00:00, 57.52it/s]\u001b[A\n",
            "Iteration: 100% 92/92 [00:01<00:00, 57.84it/s]\n",
            "Epoch:  75% 3/4 [00:07<00:02,  2.19s/it]\n",
            "Iteration:   0% 0/92 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   7% 6/92 [00:00<00:01, 59.41it/s]\u001b[A\n",
            "Iteration:  13% 12/92 [00:00<00:01, 58.38it/s]\u001b[A\n",
            "Iteration:  20% 18/92 [00:00<00:01, 58.09it/s]\u001b[A\n",
            "Iteration:  26% 24/92 [00:00<00:01, 58.28it/s]\u001b[A\n",
            "Iteration:  33% 30/92 [00:00<00:01, 58.43it/s]\u001b[A\n",
            "Iteration:  39% 36/92 [00:00<00:00, 58.16it/s]\u001b[A\n",
            "Iteration:  46% 42/92 [00:00<00:00, 57.83it/s]\u001b[A\n",
            "Iteration:  52% 48/92 [00:00<00:00, 57.80it/s]\u001b[A\n",
            "Iteration:  59% 54/92 [00:00<00:00, 58.28it/s]\u001b[A\n",
            "Iteration:  65% 60/92 [00:01<00:00, 58.53it/s]\u001b[A\n",
            "Iteration:  72% 66/92 [00:01<00:00, 58.76it/s]\u001b[A\n",
            "Iteration:  78% 72/92 [00:01<00:00, 58.86it/s]\u001b[A\n",
            "Iteration:  85% 78/92 [00:01<00:00, 58.56it/s]\u001b[A\n",
            "Iteration:  91% 84/92 [00:01<00:00, 58.65it/s]\u001b[A\n",
            "Iteration: 100% 92/92 [00:01<00:00, 58.27it/s]\n",
            "Epoch: 100% 4/4 [00:09<00:00,  2.26s/it]\n",
            "[INFO|configuration_utils.py:447] 2022-12-01 01:41:18,287 >> Configuration saved in ./train_models/bert-tiny-finetuned-cuad/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-12-01 01:41:18,318 >> Model weights saved in ./train_models/bert-tiny-finetuned-cuad/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2125] 2022-12-01 01:41:18,318 >> tokenizer config file saved in ./train_models/bert-tiny-finetuned-cuad/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2132] 2022-12-01 01:41:18,319 >> Special tokens file saved in ./train_models/bert-tiny-finetuned-cuad/special_tokens_map.json\n",
            "[INFO|configuration_utils.py:652] 2022-12-01 01:41:18,340 >> loading configuration file ./train_models/bert-tiny-finetuned-cuad/config.json\n",
            "[INFO|configuration_utils.py:706] 2022-12-01 01:41:18,340 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"./train_models/bert-tiny-finetuned-cuad\",\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:2155] 2022-12-01 01:41:18,341 >> loading weights file ./train_models/bert-tiny-finetuned-cuad/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:2608] 2022-12-01 01:41:18,392 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
            "\n",
            "[INFO|modeling_utils.py:2616] 2022-12-01 01:41:18,392 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at ./train_models/bert-tiny-finetuned-cuad.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-12-01 01:41:18,393 >> loading file vocab.txt\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-12-01 01:41:18,393 >> loading file added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-12-01 01:41:18,393 >> loading file special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1773] 2022-12-01 01:41:18,393 >> loading file tokenizer_config.json\n",
            "[INFO|configuration_utils.py:652] 2022-12-01 01:41:18,422 >> loading configuration file ./train_models/bert-tiny-finetuned-cuad/config.json\n",
            "[INFO|configuration_utils.py:706] 2022-12-01 01:41:18,423 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"./train_models/bert-tiny-finetuned-cuad\",\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 128,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 512,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 2,\n",
            "  \"num_hidden_layers\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:2155] 2022-12-01 01:41:18,423 >> loading weights file ./train_models/bert-tiny-finetuned-cuad/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:2608] 2022-12-01 01:41:18,467 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
            "\n",
            "[INFO|modeling_utils.py:2616] 2022-12-01 01:41:18,467 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at ./train_models/bert-tiny-finetuned-cuad.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
            "balanced_subset_cached_dev_bert-tiny-finetuned-cuad_512\n",
            "100% 4/4 [00:05<00:00,  1.43s/it]\n",
            "convert squad examples to features: 100% 164/164 [07:45<00:00,  2.84s/it]\n",
            "add example index and unique id: 100% 164/164 [00:00<00:00, 31123.74it/s]\n",
            "Evaluating: 100% 1120/1120 [00:06<00:00, 169.14it/s]\n",
            "OrderedDict([('exact', 60.36585365853659), ('f1', 60.36585365853659), ('total', 164), ('HasAns_exact', 0.0), ('HasAns_f1', 0.0), ('HasAns_total', 65), ('NoAns_exact', 100.0), ('NoAns_f1', 100.0), ('NoAns_total', 99), ('best_exact', 60.36585365853659), ('best_exact_thresh', 0.0), ('best_f1', 60.36585365853659), ('best_f1_thresh', 0.0)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/cuad/evaluate.py"
      ],
      "metadata": {
        "id": "IulahqgB57Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RoBERTA-Base-FineTuned-CUAD"
      ],
      "metadata": {
        "id": "F6HMfnFichHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/gustavhartz/roberta-base-cuad-finetuned"
      ],
      "metadata": {
        "id": "yFMZiHtAcFo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For every model, changes are made in the run.sh file manually and executed. Parameters changes: output_dir, model_type, model_name_or_path\n",
        "! sh /content/cuad/run.sh"
      ],
      "metadata": {
        "id": "7jW3Ab72cFv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/cuad/evaluate.py"
      ],
      "metadata": {
        "id": "8ZpIrW1TcQFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distilbert-base-uncased-finetuned-CUAD"
      ],
      "metadata": {
        "id": "eP2PLgFFcrsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/leabum/distilbert-base-uncased-finetuned-cuad"
      ],
      "metadata": {
        "id": "0jQmfTIpcgeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! sh /content/cuad/run.sh"
      ],
      "metadata": {
        "id": "rH3zIzdOeaLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/cuad/evaluate.py"
      ],
      "metadata": {
        "id": "TF8AVzScefSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bert Based uncased"
      ],
      "metadata": {
        "id": "6yzWlodYevu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/bert-base-uncased"
      ],
      "metadata": {
        "id": "g6ZNOoeSe3pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! sh /content/cuad/run.sh"
      ],
      "metadata": {
        "id": "VgNz_82bfEo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/cuad/evaluate.py"
      ],
      "metadata": {
        "id": "_tOQZsaSfHsV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}