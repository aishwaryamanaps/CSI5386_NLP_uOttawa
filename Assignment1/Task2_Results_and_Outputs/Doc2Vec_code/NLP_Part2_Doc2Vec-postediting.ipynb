{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0496979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code reference: https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py\n",
    "#Code reference: https://www.tutorialspoint.com/gensim/gensim_doc2vec_model.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c62eb7",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac975141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import re\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3454c69",
   "metadata": {},
   "source": [
    "### Reading File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bddfa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/daksh/OneDrive/Desktop/sts2016-english-with-gs-v1.0/sts2016-english-with-gs-v1.0/STS2016.input.postediting.txt', 'r', encoding='utf-8') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f928298d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not only PAMPLEMOUSSE - according to experts, even orange juice and apple contain substances that inhibit medicines.\\tThat FEBRUARY PAMPLEMOUSSE- According to the experts, even the orange juice and apple contains substances that inhibit the medicines.\\tEAMT11 post-editting dataset (http://staffwww.dcs.shef.ac.uk/people/L.Specia/resources) target_postedited\\tEAMT11 post-editting dataset (http://staffwww.dcs.shef.ac.uk/people/L.Specia/resources) target\\nThe fact that the OSCE, during the evaluation of the campaign, has highlighted the positive changes rather than the shortcomings, such as the ban to run for a third of the candidates for the opposition, referred to a prior appeasement.\\tThe fact that the OSCE, during the evaluation of the campaign, has highlighted the positive changes rather than on shortcomings, such as the ban to run for a third of the candidates for the opposition, referred to a prior appeasement.\\tEAMT11 post-editting dataset (http://staffwww.dcs.shef.ac.uk/people/L.Specia/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e410ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1448267"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5944af1c",
   "metadata": {},
   "source": [
    "### Pre-process and Tag the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4da31f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1 = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', data)\n",
    "tp2 = re.sub(r'\\d+', '', tp1)\n",
    "clean= re.compile('<.*?>')\n",
    "tp4 = re.sub(clean, '', tp2)\n",
    "tp5 = tp4.lower()\n",
    "tp7 = re.sub(r'[^\\w\\s]', '',tp5)\n",
    "tp8 = re.sub(r'[^\\x00-\\x7f]',r'', tp7)\n",
    "tp9 = tp8.replace(\"_\",\"\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0f2019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"doc2vec4.txt\", 'w') as file:\n",
    "    file.write(\"%s\\n\" % tp9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "312162a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First_Question</th>\n",
       "      <th>Second_Question</th>\n",
       "      <th>irr1</th>\n",
       "      <th>irr2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the fact that the osce during the evaluation o...</td>\n",
       "      <td>the fact that the osce during the evaluation o...</td>\n",
       "      <td>eamt posteditting dataset  targetpostedited</td>\n",
       "      <td>eamt posteditting dataset  target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in the czech republic no chance say the mobile...</td>\n",
       "      <td>in the czech republic no chance say the mobile...</td>\n",
       "      <td>eamt posteditting dataset  target</td>\n",
       "      <td>eamt posteditting dataset  targetpostedited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i already knew the word thanks to my mangas</td>\n",
       "      <td>i already knew thanks to my mangas</td>\n",
       "      <td>eamt posteditting dataset  targetpostedited</td>\n",
       "      <td>eamt posteditting dataset  target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>before off for the us nicolas sarkozy will tak...</td>\n",
       "      <td>before leaving for the us nicolas sarkozy will...</td>\n",
       "      <td>eamt posteditting dataset  target</td>\n",
       "      <td>eamt posteditting dataset  targetpostedited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and even if we could prove that for man how co...</td>\n",
       "      <td>and even if we could prove that for man how co...</td>\n",
       "      <td>eamt posteditting dataset  targetpostedited</td>\n",
       "      <td>eamt posteditting dataset  target</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      First_Question  \\\n",
       "0  the fact that the osce during the evaluation o...   \n",
       "1  in the czech republic no chance say the mobile...   \n",
       "2        i already knew the word thanks to my mangas   \n",
       "3  before off for the us nicolas sarkozy will tak...   \n",
       "4  and even if we could prove that for man how co...   \n",
       "\n",
       "                                     Second_Question  \\\n",
       "0  the fact that the osce during the evaluation o...   \n",
       "1  in the czech republic no chance say the mobile...   \n",
       "2                 i already knew thanks to my mangas   \n",
       "3  before leaving for the us nicolas sarkozy will...   \n",
       "4  and even if we could prove that for man how co...   \n",
       "\n",
       "                                          irr1  \\\n",
       "0  eamt posteditting dataset  targetpostedited   \n",
       "1            eamt posteditting dataset  target   \n",
       "2  eamt posteditting dataset  targetpostedited   \n",
       "3            eamt posteditting dataset  target   \n",
       "4  eamt posteditting dataset  targetpostedited   \n",
       "\n",
       "                                          irr2  \n",
       "0            eamt posteditting dataset  target  \n",
       "1  eamt posteditting dataset  targetpostedited  \n",
       "2            eamt posteditting dataset  target  \n",
       "3  eamt posteditting dataset  targetpostedited  \n",
       "4            eamt posteditting dataset  target  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('doc2vec4.txt', sep='\\t')\n",
    "df.columns = ['First_Question','Second_Question','irr1','irr2']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f9a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_removedStop'] = df['First_Question'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "df['second_removedStop'] = df['Second_Question'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d71b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['First_Question','Second_Question','irr1','irr2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe69252e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3286, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f91b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    corpus.append(row['first_removedStop'])\n",
    "    corpus.append(row['second_removedStop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b0aed23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fact osce evaluation campaign highlighted positive changes rather shortcomings ban run third candidates opposition referred prior appeasement',\n",
       " 'fact osce evaluation campaign highlighted positive changes rather shortcomings ban run third candidates opposition referred prior appeasement',\n",
       " 'czech republic chance say mobile operators',\n",
       " 'czech republic chance say mobile operators',\n",
       " 'already knew word thanks mangas']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd7377ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "questions1 = df['first_removedStop'].to_list()\n",
    "questions2 = df['second_removedStop'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b434a73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(questions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faf93508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls = [\"This\",\"is\",\"list\",\"of\", \"words\"]\n",
    "\n",
    "def tagged_document(list_of_list_of_words):\n",
    "    for i, list_of_words in enumerate(list_of_list_of_words):\n",
    "        tokens = gensim.utils.simple_preprocess(list_of_words)\n",
    "        yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "data_for_training = list(tagged_document(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1749471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['fact', 'osce', 'evaluation', 'campaign', 'highlighted', 'positive', 'changes', 'rather', 'shortcomings', 'ban', 'run', 'third', 'candidates', 'opposition', 'referred', 'prior', 'appeasement'], tags=[0]), TaggedDocument(words=['fact', 'osce', 'evaluation', 'campaign', 'highlighted', 'positive', 'changes', 'rather', 'shortcomings', 'ban', 'run', 'third', 'candidates', 'opposition', 'referred', 'prior', 'appeasement'], tags=[1]), TaggedDocument(words=['czech', 'republic', 'chance', 'say', 'mobile', 'operators'], tags=[2])]\n"
     ]
    }
   ],
   "source": [
    "print(data_for_training[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a382f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "model.build_vocab(data_for_training)\n",
    "\n",
    "model.train(data_for_training, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "#embeddings2 = model.train(quest2, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "955db8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.993628978729248),\n",
       " (1827, 0.846962034702301),\n",
       " (4113, 0.8447048664093018),\n",
       " (3479, 0.8346331715583801),\n",
       " (5042, 0.8335431218147278),\n",
       " (1229, 0.8291702270507812),\n",
       " (3132, 0.8275589346885681),\n",
       " (1645, 0.8266435265541077),\n",
       " (3693, 0.8255499601364136),\n",
       " (3791, 0.8237966299057007)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dv.most_similar(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0e5f72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['fact', 'osce', 'evaluation', 'campaign', 'highlighted', 'positive', 'changes', 'rather', 'shortcomings', 'ban', 'run', 'third', 'candidates', 'opposition', 'referred', 'prior', 'appeasement'], tags=[0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_training[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23836e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['members', 'opposition', 'parliament', 'appointed', 'elected'], tags=[3133])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_training[3133]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "919e8880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6572"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f335c",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "615b6940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3286"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ques1 =[]\n",
    "for question in questions1:\n",
    "    tokenized_ques1.append(gensim.utils.simple_preprocess(question))\n",
    "len(tokenized_ques1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fa72137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3286"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ques2 =[]\n",
    "for question in questions2:\n",
    "    tokenized_ques2.append(gensim.utils.simple_preprocess(question))\n",
    "len(tokenized_ques2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dde515ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "sim_scores=[]\n",
    "\n",
    "#tokenized_ques2[0:2]\n",
    "\n",
    "length_ques1 = len(tokenized_ques1)\n",
    "\n",
    "for i in range(0,length_ques1):\n",
    "    #Some part taken from https://stackoverflow.com/questions/53503049/measure-similarity-between-two-documents-using-doc2vec\n",
    "    vec1 = model.infer_vector(tokenized_ques1[i])\n",
    "    vec2 = model.infer_vector(tokenized_ques2[i])\n",
    "    cos_distance = spatial.distance.cosine(vec1, vec2)\n",
    "    cos_sim = 1-cos_distance\n",
    "    sim_scores.append(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2650dea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.945909380912781,\n",
       " 4.343312084674835,\n",
       " 4.7532713413238525,\n",
       " 3.9504793286323547,\n",
       " 4.852370321750641,\n",
       " 4.916825294494629,\n",
       " 4.932498335838318,\n",
       " 4.676063060760498,\n",
       " 4.729525446891785,\n",
       " 4.857541918754578,\n",
       " 2.6484891772270203,\n",
       " 4.50373113155365,\n",
       " 2.9285672307014465,\n",
       " 4.905709326267242,\n",
       " 4.861360788345337,\n",
       " 4.437620639801025,\n",
       " 4.784626662731171,\n",
       " 4.209699034690857,\n",
       " 3.9719021320343018,\n",
       " 4.159365892410278,\n",
       " 4.263936281204224,\n",
       " 3.6478418111801147,\n",
       " 4.865594804286957,\n",
       " 3.1271320581436157,\n",
       " 4.966279864311218,\n",
       " 4.912915527820587,\n",
       " 4.782242774963379,\n",
       " 2.7681267261505127,\n",
       " 3.9016193151474,\n",
       " 4.544695317745209,\n",
       " 4.8508307337760925,\n",
       " 4.357633292675018,\n",
       " 1.3850045204162598,\n",
       " 4.146409332752228,\n",
       " 4.608508050441742,\n",
       " 4.4645801186561584,\n",
       " 4.921918511390686,\n",
       " 4.839906394481659,\n",
       " 3.140803873538971,\n",
       " 4.929653108119965,\n",
       " 4.7817301750183105,\n",
       " 3.503442108631134,\n",
       " 4.453564286231995,\n",
       " 4.904646873474121,\n",
       " 4.740030467510223,\n",
       " 3.0979150533676147,\n",
       " 4.905167520046234,\n",
       " 3.136085271835327,\n",
       " 3.1969884037971497,\n",
       " 4.390375316143036]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_scores = [(score*5) for score in sim_scores]\n",
    "sim_scores[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd3c8dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/daksh/OneDrive/Desktop/sts2016-english-with-gs-v1.0/sts2016-english-with-gs-v1.0/STS2016.input.postediting.cosine.txt', 'w') as file:\n",
    "    for score in sim_scores:\n",
    "        file.write('%s\\n' %score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
