{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0496979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code reference: https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py\n",
    "#Code reference: https://www.tutorialspoint.com/gensim/gensim_doc2vec_model.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c62eb7",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac975141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import re\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3454c69",
   "metadata": {},
   "source": [
    "### Reading File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bddfa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/daksh/OneDrive/Desktop/sts2016-english-with-gs-v1.0/sts2016-english-with-gs-v1.0/STS2016.input.headlines.txt', 'r', encoding='utf-8') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f928298d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Digital era threatens tenuous future of drive-ins\\tDigital Era Threatens Future of Drive-Ins\\tEurope Media Monitor (http://emm.newsbrief.eu)\\tEurope Media Monitor (http://emm.newsbrief.eu)\\nJessica Lal murder convict Manu Sharma gets 15-day parole\\tJessica murder Manu Sharma gets parole\\tEurope Media Monitor (http://emm.newsbrief.eu)\\tEurope Media Monitor (http://emm.newsbrief.eu)\\nUN to hold emergency DR Congo talks\\tU.N. Council to Hold Emergency DR Congo Talks\\tEurope Media Monitor (http://emm.newsbrief.eu)\\tEurope Media Monitor (http://emm.newsbrief.eu)\\nIran and IAEA resume nuclear talks\\tIran, IAEA resume nuclear talks in Tehran\\tEurope Media Monitor (http://emm.newsbrief.eu)\\tEurope Media Monitor (http://emm.newsbrief.eu)\\nThai protesters storm army headquarters\\tThai protestors storm Royal army headquarters in Bangkok\\tEurope Media Monitor (http://emm.newsbrief.eu)\\tEurope Media Monitor (http://emm.newsbrief.eu)\\n40 Still Missing in Deadly Canada Oil Train...\\t40 still missing in deadly Canada oil '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e410ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5944af1c",
   "metadata": {},
   "source": [
    "### Pre-process and Tag the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4da31f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp1 = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', data)\n",
    "tp2 = re.sub(r'\\d+', '', tp1)\n",
    "clean= re.compile('<.*?>')\n",
    "tp4 = re.sub(clean, '', tp2)\n",
    "tp5 = tp4.lower()\n",
    "tp7 = re.sub(r'[^\\w\\s]', '',tp5)\n",
    "tp8 = re.sub(r'[^\\x00-\\x7f]',r'', tp7)\n",
    "tp9 = tp8.replace(\"_\",\"\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0f2019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"doc2vec2.txt\", 'w') as file:\n",
    "    file.write(\"%s\\n\" % tp9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "312162a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First_Question</th>\n",
       "      <th>Second_Question</th>\n",
       "      <th>irr1</th>\n",
       "      <th>irr2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jessica lal murder convict manu sharma gets da...</td>\n",
       "      <td>jessica murder manu sharma gets parole</td>\n",
       "      <td>europe media monitor</td>\n",
       "      <td>europe media monitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>un to hold emergency dr congo talks</td>\n",
       "      <td>un council to hold emergency dr congo talks</td>\n",
       "      <td>europe media monitor</td>\n",
       "      <td>europe media monitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iran and iaea resume nuclear talks</td>\n",
       "      <td>iran iaea resume nuclear talks in tehran</td>\n",
       "      <td>europe media monitor</td>\n",
       "      <td>europe media monitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thai protesters storm army headquarters</td>\n",
       "      <td>thai protestors storm royal army headquarters ...</td>\n",
       "      <td>europe media monitor</td>\n",
       "      <td>europe media monitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>still missing in deadly canada oil train</td>\n",
       "      <td>still missing in deadly canada oil train crash</td>\n",
       "      <td>europe media monitor</td>\n",
       "      <td>europe media monitor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      First_Question  \\\n",
       "0  jessica lal murder convict manu sharma gets da...   \n",
       "1                un to hold emergency dr congo talks   \n",
       "2                 iran and iaea resume nuclear talks   \n",
       "3            thai protesters storm army headquarters   \n",
       "4           still missing in deadly canada oil train   \n",
       "\n",
       "                                     Second_Question                   irr1  \\\n",
       "0             jessica murder manu sharma gets parole  europe media monitor    \n",
       "1        un council to hold emergency dr congo talks  europe media monitor    \n",
       "2           iran iaea resume nuclear talks in tehran  europe media monitor    \n",
       "3  thai protestors storm royal army headquarters ...  europe media monitor    \n",
       "4     still missing in deadly canada oil train crash  europe media monitor    \n",
       "\n",
       "                    irr2  \n",
       "0  europe media monitor   \n",
       "1  europe media monitor   \n",
       "2  europe media monitor   \n",
       "3  europe media monitor   \n",
       "4  europe media monitor   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('doc2vec2.txt', sep='\\t')\n",
    "df.columns = ['First_Question','Second_Question','irr1','irr2']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f9a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_removedStop'] = df['First_Question'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "df['second_removedStop'] = df['Second_Question'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d71b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['First_Question','Second_Question','irr1','irr2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe69252e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1497, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f91b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    corpus.append(row['first_removedStop'])\n",
    "    corpus.append(row['second_removedStop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b0aed23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jessica lal murder convict manu sharma gets day parole',\n",
       " 'jessica murder manu sharma gets parole',\n",
       " 'un hold emergency dr congo talks',\n",
       " 'un council hold emergency dr congo talks',\n",
       " 'iran iaea resume nuclear talks']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd7377ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "questions1 = df['first_removedStop'].to_list()\n",
    "questions2 = df['second_removedStop'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b434a73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(questions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faf93508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls = [\"This\",\"is\",\"list\",\"of\", \"words\"]\n",
    "\n",
    "def tagged_document(list_of_list_of_words):\n",
    "    for i, list_of_words in enumerate(list_of_list_of_words):\n",
    "        tokens = gensim.utils.simple_preprocess(list_of_words)\n",
    "        yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "data_for_training = list(tagged_document(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1749471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['jessica', 'lal', 'murder', 'convict', 'manu', 'sharma', 'gets', 'day', 'parole'], tags=[0]), TaggedDocument(words=['jessica', 'murder', 'manu', 'sharma', 'gets', 'parole'], tags=[1]), TaggedDocument(words=['un', 'hold', 'emergency', 'dr', 'congo', 'talks'], tags=[2])]\n"
     ]
    }
   ],
   "source": [
    "print(data_for_training[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a382f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "model.build_vocab(data_for_training)\n",
    "\n",
    "model.train(data_for_training, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "#embeddings2 = model.train(quest2, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "955db8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1882, 0.9932394623756409),\n",
       " (1, 0.9930800199508667),\n",
       " (1623, 0.9928853511810303),\n",
       " (1745, 0.9923970103263855),\n",
       " (863, 0.9920471906661987),\n",
       " (913, 0.991890013217926),\n",
       " (908, 0.9918063879013062),\n",
       " (1387, 0.9916388988494873),\n",
       " (1750, 0.9912846684455872),\n",
       " (875, 0.9911544322967529)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dv.most_similar(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0e5f72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['jessica', 'lal', 'murder', 'convict', 'manu', 'sharma', 'gets', 'day', 'parole'], tags=[0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_training[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23836e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['saudi', 'womens', 'driving', 'kicks', 'without', 'arrests'], tags=[1132])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_training[1132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "919e8880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2994"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f335c",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "615b6940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1497"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ques1 =[]\n",
    "for question in questions1:\n",
    "    tokenized_ques1.append(gensim.utils.simple_preprocess(question))\n",
    "len(tokenized_ques1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fa72137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1497"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ques2 =[]\n",
    "for question in questions2:\n",
    "    tokenized_ques2.append(gensim.utils.simple_preprocess(question))\n",
    "len(tokenized_ques2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dde515ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "sim_scores=[]\n",
    "\n",
    "#tokenized_ques2[0:2]\n",
    "\n",
    "length_ques1 = len(tokenized_ques1)\n",
    "\n",
    "for i in range(0,length_ques1):\n",
    "    #Some part taken from https://stackoverflow.com/questions/53503049/measure-similarity-between-two-documents-using-doc2vec\n",
    "    vec1 = model.infer_vector(tokenized_ques1[i])\n",
    "    vec2 = model.infer_vector(tokenized_ques2[i])\n",
    "    cos_distance = spatial.distance.cosine(vec1, vec2)\n",
    "    cos_sim = 1-cos_distance\n",
    "    sim_scores.append(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2650dea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.53856498003006,\n",
       " 4.954219162464142,\n",
       " 4.441409409046173,\n",
       " 4.160660803318024,\n",
       " 4.841306209564209,\n",
       " 4.965546429157257,\n",
       " 4.87661749124527,\n",
       " 4.793577492237091,\n",
       " 4.628312289714813,\n",
       " 4.946720004081726,\n",
       " 4.221621453762054,\n",
       " 4.800498187541962,\n",
       " 4.9482908844947815,\n",
       " 4.325942397117615,\n",
       " 4.869650900363922,\n",
       " 4.475871920585632,\n",
       " 4.907644987106323,\n",
       " 4.846101403236389,\n",
       " 3.8619956374168396,\n",
       " 4.967547357082367,\n",
       " 4.861205518245697,\n",
       " 4.841703772544861,\n",
       " 4.659973978996277,\n",
       " 4.744198024272919,\n",
       " 4.902806878089905,\n",
       " 4.669161438941956,\n",
       " 4.575960040092468,\n",
       " 4.80020135641098,\n",
       " 3.2185643911361694,\n",
       " 4.988655745983124,\n",
       " 4.9781882762908936,\n",
       " 4.89604264497757,\n",
       " 4.274393618106842,\n",
       " 4.978205561637878,\n",
       " 4.909103512763977,\n",
       " 3.395756185054779,\n",
       " 3.6796683073043823,\n",
       " 4.219439625740051,\n",
       " 4.693052172660828,\n",
       " 4.765040576457977,\n",
       " 4.269209206104279,\n",
       " 4.551390111446381,\n",
       " 4.319972097873688,\n",
       " 4.938136041164398,\n",
       " 4.882149398326874,\n",
       " 4.937873482704163,\n",
       " 4.853110611438751,\n",
       " 4.727130830287933,\n",
       " 2.790728807449341,\n",
       " 3.457280695438385]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_scores = [(score*5) for score in sim_scores]\n",
    "sim_scores[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd3c8dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/daksh/OneDrive/Desktop/sts2016-english-with-gs-v1.0/sts2016-english-with-gs-v1.0/STS2016.input.headlines.cosine.txt', 'w') as file:\n",
    "    for score in sim_scores:\n",
    "        file.write('%s\\n' %score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
